# üèóÔ∏è Arquitectura T√©cnica: Syntergic AI Platform
## Patrones de Desarrollo, Best Practices y Dise√±o de Sistema

---

## üìê PRINCIPIOS DE DISE√ëO

### 1. Separation of Concerns
```
Domain Layer (Teor√≠a Sint√©rgica) ‚Üê‚Üí Application Layer (IA/ML) ‚Üê‚Üí Presentation (3D/UI)
```

### 2. Real-time First
- WebSocket como comunicaci√≥n principal
- Estado reactivo (Zustand transient updates)
- Shaders optimizados (60 FPS m√≠nimo)

### 3. Scientific Rigor
- M√©tricas validadas (papers peer-reviewed)
- Logging exhaustivo para replicabilidad
- Versionado de modelos (sem√°ntico)

### 4. Open Science
- C√≥digo abierto (MIT License)
- Datasets p√∫blicos
- APIs documentadas (OpenAPI/Swagger)

---

## üéØ ARQUITECTURA ACTUAL (v0.2) - MEJORADA

### Backend Architecture (Python)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        FASTAPI APP                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ   Routes     ‚îÇ    ‚îÇ  WebSocket   ‚îÇ    ‚îÇ   Models     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   /api/*     ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚î§   /ws/*      ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚î§  (Pydantic)  ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ         ‚îÇ                    ‚îÇ                    ‚ñ≤        ‚îÇ
‚îÇ         ‚ñº                    ‚ñº                    ‚îÇ        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ           SYNTERGIC BRAIN (Inference Engine)        ‚îÇ  ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ VAE Model (PyTorch)                              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ EEG Dataset Loaders (PhysioNet)                  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ State Machine (RELAX/FOCUS modes)                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Metrics Calculator (Coherence, Entropy, Focal)   ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ         ‚îÇ                                                   ‚îÇ
‚îÇ         ‚ñº                                                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ              AI/ML LAYER                             ‚îÇ  ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ model.py   ‚îÇ  ‚îÇ train.py   ‚îÇ  ‚îÇ dataset.py ‚îÇ     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ (VAE Arch) ‚îÇ  ‚îÇ (Training) ‚îÇ  ‚îÇ (PhysioNet)‚îÇ     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
                          ‚ñº WebSocket (JSON)
                          ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    FRONTEND (React/Three.js)                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Estructura de Directorios Mejorada

```
backend/
‚îú‚îÄ‚îÄ main.py                      # FastAPI entry point
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ settings.py              # Configuraci√≥n (env vars)
‚îÇ   ‚îî‚îÄ‚îÄ logging.yaml             # Logging config
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îú‚îÄ‚îÄ routes.py                # REST endpoints
‚îÇ   ‚îî‚îÄ‚îÄ websocket.py             # WebSocket handlers
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ schemas.py               # Pydantic models
‚îú‚îÄ‚îÄ ai/
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ vae.py              # Variational Autoencoder
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ transformer.py      # ‚Üê NUEVO: Temporal model
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ base.py             # Abstract base classes
‚îÇ   ‚îú‚îÄ‚îÄ training/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ trainer.py          # Training loop
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ callbacks.py        # W&B logging, checkpoints
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ losses.py           # Custom loss functions
‚îÇ   ‚îú‚îÄ‚îÄ inference/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ predictor.py        # Real-time inference
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ batch.py            # Batch processing
‚îÇ   ‚îî‚îÄ‚îÄ data/
‚îÇ       ‚îú‚îÄ‚îÄ dataset.py          # EEG dataset class
‚îÇ       ‚îú‚îÄ‚îÄ transforms.py       # Data augmentation
‚îÇ       ‚îî‚îÄ‚îÄ loaders.py          # DataLoader configs
‚îú‚îÄ‚îÄ analysis/                    # ‚Üê NUEVO M√ìDULO
‚îÇ   ‚îú‚îÄ‚îÄ spectral.py             # FFT, bandas de frecuencia
‚îÇ   ‚îú‚îÄ‚îÄ coherence.py            # Inter-hemispheric coherence
‚îÇ   ‚îú‚îÄ‚îÄ entropy.py              # Shannon, sample entropy
‚îÇ   ‚îú‚îÄ‚îÄ connectivity.py         # PLV, Granger causality
‚îÇ   ‚îî‚îÄ‚îÄ metrics.py              # M√©tricas sint√©rgicas
‚îú‚îÄ‚îÄ hardware/                    # ‚Üê NUEVO M√ìDULO
‚îÇ   ‚îú‚îÄ‚îÄ lsl_stream.py           # Lab Streaming Layer
‚îÇ   ‚îú‚îÄ‚îÄ openbci.py              # OpenBCI connector
‚îÇ   ‚îî‚îÄ‚îÄ muse.py                 # Muse headband
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ brain_service.py        # Business logic
‚îÇ   ‚îî‚îÄ‚îÄ session_manager.py      # User sessions
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ logger.py
‚îÇ   ‚îî‚îÄ‚îÄ validators.py
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ test_vae.py
‚îÇ   ‚îú‚îÄ‚îÄ test_metrics.py
‚îÇ   ‚îî‚îÄ‚îÄ test_api.py
‚îî‚îÄ‚îÄ requirements.txt
```

---

## üé® FRONTEND ARCHITECTURE (React/Three.js)

### Estructura Mejorada

```
frontend/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ main.jsx                 # Entry point
‚îÇ   ‚îú‚îÄ‚îÄ App.jsx                  # Root component
‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ canvas/              # 3D Components
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Experience.jsx   # R3F Canvas wrapper
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Brain.jsx        # Brain mesh + logic
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ LatticeMesh.jsx  # ‚Üê SEPARADO: Lattice grid
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ FocalOrb.jsx     # ‚Üê SEPARADO: Conscious marker
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Environment.jsx  # Lights, background
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hud/                 # ‚Üê NUEVO: UI Overlays
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ CoherenceMeter.jsx    # Real-time graph
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ FrequencySpectrum.jsx # FFT visualization
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ StateIndicator.jsx    # Meditation state
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ SessionStats.jsx      # Duration, avg coherence
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ controls/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ModeSelector.jsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ RecordButton.jsx      # ‚Üê NUEVO
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ CalibrationWizard.jsx # ‚Üê NUEVO
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ panels/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ ContextPanel.jsx      # Teor√≠a explicativa
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ SettingsPanel.jsx     # ‚Üê NUEVO
‚îÇ   ‚îú‚îÄ‚îÄ shaders/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SyntergicMaterial.js      # Brain shader
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ LatticeMaterial.js        # ‚Üê NUEVO: Grid shader
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ParticleSystem.js         # ‚Üê NUEVO: Quantum particles
‚îÇ   ‚îú‚îÄ‚îÄ store/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ brainStore.js             # Zustand state
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sessionStore.js           # ‚Üê NUEVO: Session data
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ settingsStore.js          # ‚Üê NUEVO: User prefs
‚îÇ   ‚îú‚îÄ‚îÄ hooks/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ useWebSocket.js           # WebSocket connection
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ useBrainMetrics.js        # ‚Üê NUEVO: Derived metrics
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ useAudioFeedback.js       # ‚Üê NUEVO: Binaural beats
‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mathUtils.js
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ colorUtils.js             # Coherence ‚Üí Color mapping
‚îÇ   ‚îî‚îÄ‚îÄ styles/
‚îÇ       ‚îî‚îÄ‚îÄ global.css
‚îú‚îÄ‚îÄ public/
‚îÇ   ‚îî‚îÄ‚îÄ models/
‚îÇ       ‚îî‚îÄ‚îÄ brain/
‚îÇ           ‚îî‚îÄ‚îÄ scene.gltf
‚îî‚îÄ‚îÄ package.json
```

### Estado Global (Zustand) - Mejorado

```javascript
// store/brainStore.js
import { create } from 'zustand'
import { subscribeWithSelector } from 'zustand/middleware'

export const useBrainStore = create(
  subscribeWithSelector((set, get) => ({
    // WebSocket Connection
    ws: null,
    isConnected: false,
    
    // Real-time Metrics (transient - no re-render)
    coherence: 0.5,
    entropy: 0.5,
    focalPoint: { x: 0, y: 0, z: 0 },
    frequency: 10.0,
    
    // Frequency Bands (NUEVO)
    bands: {
      delta: 0,   // 0.5-4 Hz
      theta: 0,   // 4-8 Hz
      alpha: 0,   // 8-13 Hz
      beta: 0,    // 13-30 Hz
      gamma: 0    // 30-50 Hz
    },
    
    // Session Data
    sessionStartTime: null,
    sessionDuration: 0,
    coherenceHistory: [], // Array de {timestamp, coherence}
    
    // User State
    currentMode: 'focus', // 'relax' | 'focus' | 'custom'
    isRecording: false,
    
    // Actions
    connect: (url) => {
      const ws = new WebSocket(url)
      ws.onopen = () => set({ isConnected: true, ws })
      ws.onmessage = (event) => {
        const data = JSON.parse(event.data)
        get().updateMetrics(data)
      }
      ws.onclose = () => set({ isConnected: false, ws: null })
    },
    
    updateMetrics: (data) => {
      // Transient update (no trigger re-renders)
      const state = get()
      state.coherence = data.coherence
      state.entropy = data.entropy
      state.focalPoint = data.focal_point
      state.frequency = data.frequency
      
      // Update history (persisted)
      if (state.isRecording) {
        set(state => ({
          coherenceHistory: [
            ...state.coherenceHistory,
            { timestamp: Date.now(), value: data.coherence }
          ]
        }))
      }
    },
    
    setMode: async (mode) => {
      await fetch(`http://localhost:8000/set-mode/${mode}`, { method: 'POST' })
      set({ currentMode: mode })
    },
    
    startSession: () => set({
      isRecording: true,
      sessionStartTime: Date.now(),
      coherenceHistory: []
    }),
    
    endSession: () => {
      const session = {
        duration: Date.now() - get().sessionStartTime,
        avgCoherence: get().coherenceHistory.reduce((sum, v) => sum + v.value, 0) / get().coherenceHistory.length,
        history: get().coherenceHistory
      }
      // Save to localStorage or send to backend
      localStorage.setItem('lastSession', JSON.stringify(session))
      set({ isRecording: false })
      return session
    }
  }))
)
```

---

## üî¨ M√ìDULO DE AN√ÅLISIS CIENT√çFICO (Nuevo)

### Clase Principal de M√©tricas

```python
# backend/analysis/metrics.py
import numpy as np
from scipy import signal
from scipy.stats import entropy as shannon_entropy
import mne

class SyntergicMetrics:
    """
    Calcula m√©tricas sint√©rgicas basadas en papers cient√≠ficos validados.
    """
    
    @staticmethod
    def compute_coherence(eeg_left: np.ndarray, 
                          eeg_right: np.ndarray, 
                          fs: int = 256,
                          freq_band: tuple = (8, 13)) -> float:
        """
        Coherencia inter-hemisf√©rica en banda Alpha.
        
        Referencias:
        - Nunez et al. (1997). "EEG coherency: I. Statistics, reference electrode..."
        - Thatcher et al. (2008). "Development of cortical connections..."
        
        Args:
            eeg_left: Se√±al EEG hemisferio izquierdo (1D array)
            eeg_right: Se√±al EEG hemisferio derecho (1D array)
            fs: Frecuencia de muestreo
            freq_band: Rango de frecuencias (Hz)
        
        Returns:
            float: Coherencia normalizada [0, 1]
        """
        # Welch's method para coherencia
        f, Cxy = signal.coherence(eeg_left, eeg_right, fs, nperseg=256)
        
        # Extraer banda de inter√©s
        freq_mask = (f >= freq_band[0]) & (f <= freq_band[1])
        coherence_band = np.mean(Cxy[freq_mask])
        
        return float(coherence_band)
    
    @staticmethod
    def compute_entropy(eeg_signal: np.ndarray, fs: int = 256) -> float:
        """
        Entrop√≠a de Shannon del espectro de potencia.
        Alta entrop√≠a = Caos (muchas frecuencias)
        Baja entrop√≠a = Orden (dominante en pocas frecuencias)
        
        Referencias:
        - Inouye et al. (1991). "Quantification of EEG irregularity..."
        """
        # PSD usando Welch
        f, Pxx = signal.welch(eeg_signal, fs, nperseg=256)
        
        # Normalizar a distribuci√≥n de probabilidad
        Pxx_norm = Pxx / np.sum(Pxx)
        
        # Shannon entropy
        H = shannon_entropy(Pxx_norm)
        
        # Normalizar a [0, 1]
        max_entropy = np.log(len(Pxx_norm))  # M√°xima entrop√≠a posible
        normalized_entropy = H / max_entropy
        
        return float(normalized_entropy)
    
    @staticmethod
    def compute_focal_point(eeg_channels: np.ndarray,
                           electrode_positions: dict) -> dict:
        """
        Calcula el "centro de masa" de la actividad cerebral.
        
        M√©todo simplificado de source localization.
        Para versi√≥n completa usar MNE-Python con BEM model.
        
        Args:
            eeg_channels: Array (n_channels, n_samples)
            electrode_positions: Dict {channel_name: (x, y, z)}
        
        Returns:
            dict: {'x': float, 'y': float, 'z': float}
        """
        # Power de cada canal (RMS)
        power_per_channel = np.sqrt(np.mean(eeg_channels**2, axis=1))
        
        # Normalizar
        weights = power_per_channel / np.sum(power_per_channel)
        
        # Weighted centroid
        centroid = np.zeros(3)
        for i, (ch_name, pos) in enumerate(electrode_positions.items()):
            centroid += weights[i] * np.array(pos)
        
        return {
            'x': float(centroid[0]),
            'y': float(centroid[1]),
            'z': float(centroid[2])
        }
    
    @staticmethod
    def detect_gamma_bursts(eeg_signal: np.ndarray,
                           fs: int = 256,
                           threshold: float = 2.0) -> list:
        """
        Detecta r√°fagas de actividad Gamma (40 Hz).
        Asociadas a momentos de insight ("Aha!" moments).
        
        Referencias:
        - Sheth et al. (2009). "Gamma oscillations and neural synchrony..."
        """
        # Filtrar banda Gamma (30-50 Hz)
        sos = signal.butter(4, [30, 50], btype='bandpass', fs=fs, output='sos')
        gamma_filtered = signal.sosfilt(sos, eeg_signal)
        
        # Envolvente (Hilbert transform)
        analytic_signal = signal.hilbert(gamma_filtered)
        amplitude_envelope = np.abs(analytic_signal)
        
        # Detectar picos sobre threshold (en desviaciones est√°ndar)
        mean_amp = np.mean(amplitude_envelope)
        std_amp = np.std(amplitude_envelope)
        threshold_value = mean_amp + (threshold * std_amp)
        
        peaks, _ = signal.find_peaks(amplitude_envelope, height=threshold_value)
        
        # Convertir √≠ndices a timestamps
        timestamps = peaks / fs
        
        return timestamps.tolist()
    
    @staticmethod
    def compute_all_metrics(eeg_data: dict, fs: int = 256) -> dict:
        """
        Compute completo de todas las m√©tricas sint√©rgicas.
        
        Args:
            eeg_data: Dict con estructura {
                'left_hemisphere': np.ndarray,  # Promedio Fp1, F3, C3, P3
                'right_hemisphere': np.ndarray, # Promedio Fp2, F4, C4, P4
                'all_channels': np.ndarray,     # (n_channels, n_samples)
                'electrode_positions': dict
            }
        
        Returns:
            dict: Todas las m√©tricas calculadas
        """
        return {
            'coherence': SyntergicMetrics.compute_coherence(
                eeg_data['left_hemisphere'],
                eeg_data['right_hemisphere'],
                fs
            ),
            'entropy': SyntergicMetrics.compute_entropy(
                eeg_data['left_hemisphere'],  # O promedio de ambos
                fs
            ),
            'focal_point': SyntergicMetrics.compute_focal_point(
                eeg_data['all_channels'],
                eeg_data['electrode_positions']
            ),
            'gamma_bursts': SyntergicMetrics.detect_gamma_bursts(
                eeg_data['left_hemisphere'],
                fs
            )
        }
```

---

## üéÆ PATRONES DE INTERACCI√ìN

### 1. Neurofeedback Loop

```
Usuario ‚Üí EEG ‚Üí Backend (An√°lisis) ‚Üí Frontend (Visualizaci√≥n) ‚Üí Usuario ve resultado
   ‚Üë                                                                      ‚Üì
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Ajusta estrategia mental ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 2. Progressive Enhancement

```javascript
// Funciona sin EEG (modo demo con datos simulados)
if (!eegHardwareDetected) {
  useDemoMode() // Dataset pre-grabado
}

// Mejora si hay EEG
if (eegConnected) {
  useRealTimeEEG()
}

// Ultra-mejora si hay m√∫ltiples sujetos
if (multipleSubjects) {
  enableSyntergicSync() // Coherencia cruzada
}
```

### 3. Error Handling Cient√≠fico

```python
# backend/utils/validators.py
class EEGValidator:
    @staticmethod
    def validate_signal_quality(eeg_signal: np.ndarray) -> dict:
        """
        Retorna m√©tricas de calidad de se√±al.
        """
        # 1. Rango fisiol√≥gico (EEG t√≠pico: -100 a +100 ¬µV)
        if np.max(np.abs(eeg_signal)) > 200:
            return {'valid': False, 'reason': 'Amplitud fuera de rango fisiol√≥gico'}
        
        # 2. Detectar saturaci√≥n (flat line)
        if np.std(eeg_signal) < 0.1:
            return {'valid': False, 'reason': 'Se√±al saturada o desconectada'}
        
        # 3. Detectar artefactos de movimiento (cambios bruscos)
        diff = np.diff(eeg_signal)
        if np.max(np.abs(diff)) > 50:
            return {'valid': False, 'reason': 'Artefacto de movimiento detectado'}
        
        return {'valid': True, 'reason': 'Se√±al v√°lida'}
```

---

## üìä LOGGING Y TELEMETR√çA

### Weights & Biases Integration

```python
# backend/ai/training/trainer.py
import wandb

class Trainer:
    def __init__(self, config):
        wandb.init(
            project="syntergic-ai",
            config=config,
            tags=["vae", "eeg", "meditation"]
        )
    
    def train_epoch(self, dataloader):
        for batch in dataloader:
            loss = self.compute_loss(batch)
            
            # Log m√©tricas
            wandb.log({
                "loss": loss,
                "learning_rate": self.optimizer.param_groups[0]['lr'],
                "batch_coherence": batch_metrics['coherence']
            })
            
            # Log visualizaciones cada 100 batches
            if batch_idx % 100 == 0:
                wandb.log({
                    "latent_space": wandb.Image(plot_latent_space(batch)),
                    "reconstruction": wandb.Image(plot_reconstruction(batch))
                })
```

---

## üîê SEGURIDAD Y PRIVACIDAD

### Datos Sensibles (EEG)

```python
# backend/utils/privacy.py
import hashlib

class EEGPrivacy:
    @staticmethod
    def anonymize_subject_id(subject_id: str) -> str:
        """Hash irreversible del ID"""
        return hashlib.sha256(subject_id.encode()).hexdigest()[:16]
    
    @staticmethod
    def remove_pii(eeg_data: dict) -> dict:
        """Elimina informaci√≥n personal identificable"""
        safe_data = {
            'eeg_signal': eeg_data['signal'],
            'timestamp': eeg_data['timestamp'],
            'metadata': {
                'sampling_rate': eeg_data['fs'],
                'duration': len(eeg_data['signal']) / eeg_data['fs']
            }
        }
        # NO incluir: nombre, edad, ubicaci√≥n
        return safe_data
```

---

## üöÄ DEPLOYMENT

### Docker Compose

```yaml
# docker-compose.yml
version: '3.8'

services:
  backend:
    build: ./backend
    ports:
      - "8000:8000"
    environment:
      - PYTHONUNBUFFERED=1
      - MODEL_PATH=/models/syntergic_vae.pth
    volumes:
      - ./models:/models
    command: uvicorn main:app --host 0.0.0.0 --reload
  
  frontend:
    build: ./frontend
    ports:
      - "5173:5173"
    environment:
      - VITE_API_URL=http://localhost:8000
    command: npm run dev -- --host
  
  redis:
    image: redis:alpine
    ports:
      - "6379:6379"
```

---

## üìà PERFORMANCE OPTIMIZATION

### Backend
- [ ] Redis caching para inferencias repetidas
- [ ] Batch processing para m√∫ltiples usuarios
- [ ] Model quantization (FP16 en lugar de FP32)
- [ ] ONNX runtime para inferencia m√°s r√°pida

### Frontend
- [ ] Three.js instancing para part√≠culas (1 draw call)
- [ ] Shader LOD (Level of Detail) seg√∫n FPS
- [ ] Web Workers para c√°lculos pesados
- [ ] Lazy loading de modelos 3D

---

## üß™ TESTING STRATEGY

```python
# backend/tests/test_metrics.py
import pytest
import numpy as np
from analysis.metrics import SyntergicMetrics

def test_coherence_perfect_sync():
    """Dos se√±ales id√©nticas ‚Üí coherencia = 1.0"""
    signal1 = np.sin(2 * np.pi * 10 * np.linspace(0, 1, 256))
    signal2 = signal1.copy()
    
    coherence = SyntergicMetrics.compute_coherence(signal1, signal2)
    assert coherence > 0.95  # Casi 1.0 (tolerancia num√©rica)

def test_coherence_uncorrelated():
    """Ruido aleatorio ‚Üí coherencia cercana a 0"""
    signal1 = np.random.randn(256)
    signal2 = np.random.randn(256)
    
    coherence = SyntergicMetrics.compute_coherence(signal1, signal2)
    assert coherence < 0.3
```

---

## üéì CONCLUSI√ìN

Esta arquitectura:
1. **Escalable**: Modular, f√°cil agregar nuevos modelos
2. **Cient√≠fica**: M√©tricas validadas, logging exhaustivo
3. **User-friendly**: UX progresiva, errores claros
4. **Open**: APIs p√∫blicas, c√≥digo documentado

**Pr√≥ximo paso**: Implementar m√≥dulo `analysis/` completo.
