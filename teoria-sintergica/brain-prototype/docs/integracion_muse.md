# ğŸ§ Plan de IntegraciÃ³n: Muse 2 â†’ Syntergic Brain Platform

> **Objetivo**: Conectar el hardware Muse 2 con nuestro sistema existente para capturar EEG en tiempo real.

---

## ğŸ“Š Estado Actual del Sistema

### Backend (Python/FastAPI) âœ…
```
backend/
â”œâ”€â”€ main.py              # API + WebSocket (streaming a 5Hz)
â”œâ”€â”€ models.py            # Pydantic schemas
â”œâ”€â”€ analysis/            # MÃ©tricas sintÃ©rgicas
â”‚   â”œâ”€â”€ spectral.py      # FFT, bandas de frecuencia
â”‚   â”œâ”€â”€ coherence.py     # Coherencia inter-hemisfÃ©rica
â”‚   â”œâ”€â”€ entropy.py       # EntropÃ­a espectral
â”‚   â””â”€â”€ metrics.py       # Orquestador de mÃ©tricas
â”œâ”€â”€ ai/
â”‚   â”œâ”€â”€ model.py         # VAE architecture
â”‚   â”œâ”€â”€ inference.py     # SyntergicBrain (punto de entrada)
â”‚   â””â”€â”€ session_player.py
â””â”€â”€ hardware/            # â† A CREAR
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ base.py          # Abstract base class
    â”œâ”€â”€ muse.py          # Muse 2 connector
    â””â”€â”€ lsl_stream.py    # Lab Streaming Layer utils
```

### Frontend (React/Three.js) âœ…
- Ya consume WebSocket en `ws://localhost:8000/ws/brain-state`
- No requiere cambios para integraciÃ³n de hardware

---

## ğŸ¯ Especificaciones del Muse 2

### Canales EEG
| Canal | UbicaciÃ³n | Hemisferio | Zona |
|-------|-----------|------------|------|
| **TP9** | Temporal izquierdo | Left | Temporal/Parietal |
| **AF7** | Frontal izquierdo | Left | Frontal |
| **AF8** | Frontal derecho | Right | Frontal |
| **TP10** | Temporal derecho | Right | Temporal/Parietal |

### Sensores Adicionales
- **AcelerÃ³metro**: 3 ejes (X, Y, Z) - detecciÃ³n de movimiento
- **Giroscopio**: 3 ejes - orientaciÃ³n de la cabeza
- **PPG**: Photoplethysmography - ritmo cardÃ­aco (sensor en frente)

### Especificaciones TÃ©cnicas
- **Sampling Rate EEG**: 256 Hz (vs. 160 Hz de PhysioNet)
- **ResoluciÃ³n**: 12-bit
- **ConexiÃ³n**: Bluetooth Low Energy (BLE)
- **BaterÃ­a**: ~10 horas
- **Formato datos**: LSL (Lab Streaming Layer)

---

## ğŸ”§ Stack de IntegraciÃ³n

### LibrerÃ­as Python Necesarias

```bash
# Lab Streaming Layer (core)
pip install pylsl

# Muse especÃ­fico
pip install muselsl

# Opcional: Bluetooth utilities (Linux)
pip install bleak  # Para BLE directo

# Ya instalados en requirements.txt
# mne, numpy, scipy
```

### Flujo de Datos

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         MUSE 2                                  â”‚
â”‚   TP9 â”€â”€â”€â”€â”€â”                                                    â”‚
â”‚   AF7 â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â–º Bluetooth LE                                  â”‚
â”‚   AF8 â”€â”€â”€â”€â”€â”¤                                                    â”‚
â”‚   TP10 â”€â”€â”€â”€â”˜                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MUSELSL BRIDGE                               â”‚
â”‚   muselsl stream --ppg --acc --gyro                             â”‚
â”‚           â”‚                                                     â”‚
â”‚           â–¼                                                     â”‚
â”‚   Lab Streaming Layer (LSL)                                     â”‚
â”‚   - EEG Stream @ 256 Hz                                         â”‚
â”‚   - PPG Stream                                                  â”‚
â”‚   - ACC Stream                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 BACKEND: hardware/muse.py                       â”‚
â”‚                                                                 â”‚
â”‚   class MuseConnector:                                          â”‚
â”‚     â€¢ Discover & Connect                                        â”‚
â”‚     â€¢ Buffer EEG (2 sec windows)                                â”‚
â”‚     â€¢ Resample 256Hz â†’ 160Hz (compatibilidad)                   â”‚
â”‚     â€¢ Split hemisferios (TP9+AF7 | AF8+TP10)                    â”‚
â”‚     â€¢ Generar formato compatible con SyntergicMetrics           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 BACKEND: ai/inference.py                        â”‚
â”‚                                                                 â”‚
â”‚   class SyntergicBrain:                                         â”‚
â”‚     â€¢ set_mode('muse')  â† NUEVO MODO                            â”‚
â”‚     â€¢ _process_eeg_window() â† Sin cambios                       â”‚
â”‚     â€¢ next_state() â†’ Usa MuseConnector si modo='muse'           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 WEBSOCKET â†’ FRONTEND                            â”‚
â”‚   Mismo formato JSON que ya existe                              â”‚
â”‚   { coherence, entropy, focal_point, bands, state, plv }        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ Fases de ImplementaciÃ³n

### Fase 1: MÃ³dulo Hardware Base (2-3 horas)

**Archivos a crear:**
```
backend/hardware/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ base.py        # Abstract base class para hardware
â”œâ”€â”€ lsl_utils.py   # Utilidades LSL
â””â”€â”€ muse.py        # Conector Muse 2
```

**Tareas:**
- [ ] Crear clase abstracta `EEGDevice` con interfaz comÃºn
- [ ] Implementar `MuseConnector` con mÃ©todos:
  - `discover()` - Buscar dispositivos
  - `connect(address)` - Conectar
  - `start_stream()` - Iniciar streaming
  - `get_window(duration)` - Obtener ventana EEG
  - `disconnect()` - Desconectar
- [ ] Manejar resampling 256Hz â†’ 160Hz

### Fase 2: IntegraciÃ³n con SyntergicBrain (1-2 horas)

**Modificar:**
- `ai/inference.py` - Agregar modo 'muse'
- `main.py` - Nuevos endpoints para hardware

**Nuevos endpoints:**
```
GET  /hardware/devices       # Lista dispositivos disponibles
POST /hardware/connect       # Conectar a Muse
POST /hardware/disconnect    # Desconectar
GET  /hardware/status        # Estado de conexiÃ³n
POST /set-mode/muse          # Cambiar a modo hardware
```

### Fase 3: ValidaciÃ³n y CalibraciÃ³n (2-3 horas)

**Tareas:**
- [ ] Script de test: `test_muse_connection.py`
- [ ] Comparar mÃ©tricas Muse vs Dataset (sanity check)
- [ ] Ajustar thresholds si es necesario
- [ ] Documentar proceso de calibraciÃ³n

### Fase 4: UX y Onboarding (1-2 horas)

**Frontend (opcional):**
- [ ] Indicator de conexiÃ³n hardware
- [ ] Wizard de calibraciÃ³n
- [ ] Feedback de calidad de seÃ±al

---

## ğŸ—‚ï¸ Estructura de Archivos Propuesta

### backend/hardware/__init__.py
```python
from .base import EEGDevice
from .muse import MuseConnector
from .lsl_utils import LSLStreamManager

__all__ = ['EEGDevice', 'MuseConnector', 'LSLStreamManager']
```

### backend/hardware/base.py
```python
from abc import ABC, abstractmethod
from typing import Optional, Dict, List
import numpy as np

class EEGDevice(ABC):
    """
    Abstract base class para dispositivos EEG.
    Permite agregar nuevos dispositivos (OpenBCI, etc.) fÃ¡cilmente.
    """
    
    @abstractmethod
    def discover(self) -> List[Dict]:
        """Descubre dispositivos disponibles."""
        pass
    
    @abstractmethod
    def connect(self, address: str) -> bool:
        """Conecta a un dispositivo especÃ­fico."""
        pass
    
    @abstractmethod
    def disconnect(self) -> None:
        """Desconecta del dispositivo."""
        pass
    
    @abstractmethod
    def start_stream(self) -> None:
        """Inicia el streaming de datos."""
        pass
    
    @abstractmethod
    def stop_stream(self) -> None:
        """Detiene el streaming."""
        pass
    
    @abstractmethod
    def get_window(self, duration: float) -> Optional[Dict]:
        """
        Retorna una ventana de datos EEG.
        
        Returns:
            Dict con estructura:
            {
                'data': np.ndarray,      # (n_channels, n_samples)
                'fs': int,               # Sampling rate
                'timestamp': float,      # Timestamp inicio
                'channels': List[str]    # Nombres canales
            }
        """
        pass
    
    @abstractmethod
    def get_status(self) -> Dict:
        """Retorna estado del dispositivo."""
        pass
```

---

## âš™ï¸ ConfiguraciÃ³n del Muse 2

### Primer Setup (una sola vez)

```bash
# 1. Instalar dependencias
pip install muselsl pylsl bleak

# 2. Buscar dispositivos
muselsl list

# Output esperado:
# Found 1 Muse(s):
#   Muse-XXXX : XX:XX:XX:XX:XX:XX

# 3. Test de conexiÃ³n
muselsl stream --address XX:XX:XX:XX:XX:XX

# En otra terminal:
muselsl view  # Visualizar ondas en tiempo real
```

### En macOS (notas importantes)

```bash
# macOS requiere permisos de Bluetooth
# System Preferences â†’ Security & Privacy â†’ Privacy â†’ Bluetooth

# Si hay problemas de conexiÃ³n:
brew install blueutil
blueutil --power 0 && blueutil --power 1  # Reset Bluetooth
```

### En Linux

```bash
# Asegurar que el usuario tiene permisos Bluetooth
sudo usermod -a -G bluetooth $USER

# Reiniciar servicio
sudo systemctl restart bluetooth
```

---

## ğŸ”Œ Mapping de Canales: Muse 2 â†’ Sistema Actual

### Problema
El sistema actual espera 64 canales (PhysioNet), Muse 2 tiene 4.

### SoluciÃ³n: Adaptador

```python
class MuseToSyntergicAdapter:
    """
    Adapta datos de 4 canales Muse a formato compatible con el sistema.
    """
    
    # Mapeo de canales Muse
    MUSE_CHANNELS = {
        0: 'TP9',   # Temporal izquierdo
        1: 'AF7',   # Frontal izquierdo
        2: 'AF8',   # Frontal derecho
        3: 'TP10'   # Temporal derecho
    }
    
    # Hemisferios
    LEFT_CHANNELS = [0, 1]   # TP9, AF7
    RIGHT_CHANNELS = [2, 3]  # AF8, TP10
    
    @staticmethod
    def prepare_for_analysis(muse_data: np.ndarray, fs: int = 256) -> Dict:
        """
        Prepara datos Muse para SyntergicMetrics.
        
        Args:
            muse_data: Array (4, n_samples)
            fs: Sampling rate
            
        Returns:
            Dict compatible con SyntergicMetrics.compute_all()
        """
        # Promedio hemisferio izquierdo (TP9 + AF7)
        left_avg = np.mean(muse_data[MuseToSyntergicAdapter.LEFT_CHANNELS], axis=0)
        
        # Promedio hemisferio derecho (AF8 + TP10)
        right_avg = np.mean(muse_data[MuseToSyntergicAdapter.RIGHT_CHANNELS], axis=0)
        
        # SeÃ±al global (promedio de todo)
        signal_avg = np.mean(muse_data, axis=0)
        
        return {
            'signal': signal_avg,
            'left_hemisphere': left_avg,
            'right_hemisphere': right_avg,
            'raw_variance': np.var(muse_data)
        }
```

### Para el VAE (opcional)
Si queremos usar el VAE pre-entrenado, necesitamos padding:

```python
def pad_for_vae(muse_data: np.ndarray, target_shape=(64, 161)) -> np.ndarray:
    """
    Expande 4 canales a 64 mediante padding/repeticiÃ³n.
    
    NOTA: El VAE no fue entrenado con datos Muse,
    asÃ­ que las inferencias de focal_point serÃ¡n aproximadas.
    Para v1, usamos solo las mÃ©tricas espectrales (FFT, coherencia)
    que NO dependen del VAE.
    """
    n_channels_muse, n_samples = muse_data.shape
    
    # Resampling temporal si es necesario
    if n_samples != target_shape[1]:
        from scipy import signal
        muse_data = signal.resample(muse_data, target_shape[1], axis=1)
    
    # Padding de canales: repetir patrÃ³n para llenar 64
    # TP9, AF7, AF8, TP10 â†’ Repetir 16 veces
    padded = np.tile(muse_data, (16, 1))  # (64, 161)
    
    return padded
```

---

## ğŸ“Š MÃ©tricas Prioritarias (Muse 2)

### MÃ©tricas que FUNCIONAN PERFECTO con 4 canales:
1. âœ… **Coherencia Alpha** (TP9 â†” TP10, AF7 â†” AF8)
2. âœ… **Bandas de frecuencia** (Delta, Theta, Alpha, Beta, Gamma)
3. âœ… **EntropÃ­a espectral**
4. âœ… **Estado mental** (meditation, focus, relaxed)
5. âœ… **PLV** (Phase Locking Value)
6. âœ… **Frecuencia dominante**

### MÃ©tricas con LIMITACIONES:
1. âš ï¸ **Focal Point 3D**: Solo aproximado (4 puntos, no mapeo completo)
2. âš ï¸ **Source Localization**: No viable con 4 canales
3. âš ï¸ **TopografÃ­a completa**: Imposible (solo 4 ubicaciones)

### DecisiÃ³n de DiseÃ±o
**Para v1 con Muse 2**: 
- Usar anÃ¡lisis espectral directo (no VAE)
- El VAE se puede omitir o usar con disclaimer
- Focal point puede ser sintÃ©tico basado en bandas

---

## ğŸ§ª Scripts de Testing

### test_muse_connection.py
```python
#!/usr/bin/env python3
"""
Test de conexiÃ³n con Muse 2.
Ejecutar: python test_muse_connection.py
"""

from muselsl import list_muses, stream
from pylsl import StreamInlet, resolve_byprop
import time
import numpy as np

def test_discovery():
    """Test: Descubrir dispositivos"""
    print("ğŸ” Buscando dispositivos Muse...")
    muses = list_muses()
    
    if not muses:
        print("âŒ No se encontraron dispositivos Muse")
        print("   â†’ AsegÃºrate de que el Muse estÃ© encendido")
        print("   â†’ Bluetooth debe estar activado")
        return None
    
    print(f"âœ… Encontrados {len(muses)} dispositivo(s):")
    for m in muses:
        print(f"   â€¢ {m['name']} : {m['address']}")
    
    return muses[0]['address']

def test_stream(address: str, duration: int = 10):
    """Test: Streaming de datos"""
    print(f"\nğŸ“¡ Conectando a {address}...")
    
    # Iniciar stream en background
    import subprocess
    import threading
    
    stream_process = subprocess.Popen(
        ['muselsl', 'stream', '--address', address],
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE
    )
    
    time.sleep(5)  # Esperar conexiÃ³n
    
    # Resolver stream EEG
    print("ğŸ”Œ Buscando stream EEG en LSL...")
    streams = resolve_byprop('type', 'EEG', timeout=10)
    
    if not streams:
        print("âŒ No se encontrÃ³ stream EEG")
        stream_process.terminate()
        return False
    
    print(f"âœ… Stream encontrado: {streams[0].name()}")
    
    # Crear inlet
    inlet = StreamInlet(streams[0])
    
    # Capturar datos
    print(f"\nğŸ“Š Capturando {duration} segundos de datos...")
    samples = []
    start_time = time.time()
    
    while time.time() - start_time < duration:
        sample, timestamp = inlet.pull_sample(timeout=1.0)
        if sample:
            samples.append(sample)
    
    samples = np.array(samples)
    print(f"âœ… Capturados {len(samples)} samples")
    print(f"   Forma: {samples.shape}")
    print(f"   Sampling rate efectivo: {len(samples)/duration:.1f} Hz")
    print(f"   Rango valores: [{samples.min():.2f}, {samples.max():.2f}] ÂµV")
    
    # Calcular mÃ©tricas bÃ¡sicas
    print("\nğŸ“ˆ MÃ©tricas bÃ¡sicas:")
    for i, ch in enumerate(['TP9', 'AF7', 'AF8', 'TP10']):
        std = np.std(samples[:, i])
        print(f"   {ch}: Ïƒ = {std:.2f} ÂµV")
    
    # Cleanup
    stream_process.terminate()
    
    return True

if __name__ == '__main__':
    address = test_discovery()
    if address:
        test_stream(address)
```

---

## ğŸ“… Timeline Estimado

| Fase | DuraciÃ³n | DescripciÃ³n |
|------|----------|-------------|
| **1. Setup Hardware** | 30 min | Instalar libs, test conexiÃ³n |
| **2. MÃ³dulo base.py** | 1 hora | Abstract class, tipos |
| **3. MÃ³dulo muse.py** | 2 horas | Conector completo |
| **4. IntegraciÃ³n inference.py** | 1.5 horas | Nuevo modo 'muse' |
| **5. Endpoints API** | 1 hora | /hardware/* routes |
| **6. Testing** | 1.5 horas | Scripts de validaciÃ³n |
| **7. DocumentaciÃ³n** | 30 min | README, comentarios |

**Total estimado**: ~8 horas de desarrollo

---

## ğŸš€ PrÃ³ximos Pasos

1. **Instalar muselsl** y verificar que detecta el Muse 2
2. **Crear estructura** `backend/hardware/`
3. **Implementar** `muse.py` con buffer circular
4. **Integrar** con `SyntergicBrain.set_mode('muse')`
5. **Testear** mÃ©tricas en tiempo real
6. **Opcional**: Actualizar frontend con indicador de hardware

---

## ğŸ“š Referencias

- [muselsl Documentation](https://github.com/alexandrebarachant/muse-lsl)
- [pylsl Tutorial](https://labstreaminglayer.readthedocs.io/)
- [Muse Research Tools](https://choosemuse.com/development/)
- [MNE-Python LSL](https://mne.tools/mne-lsl/)

---

*Documento creado para brain-prototype v0.3*
*Ãšltima actualizaciÃ³n: Enero 2026*